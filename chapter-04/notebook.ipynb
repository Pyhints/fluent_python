{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 4 : Unicode Text Versus Bytes\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic concepts\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### what is str, character, code-point, encoding, bytes\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Humans use text  \n",
    "Computers speak bytes\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| terms                          | definition                                                                                                                                                                  | example                                                   |\n",
    "| ------------------------------ | --------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | --------------------------------------------------------- |\n",
    "| code-point                     | 1 `Character` = 1 `Code-point` <br/> **purpose**: every character &rarr; number-id <br/> Fonts work on character to show [Grapheme](https://en.wikipedia.org/wiki/Grapheme) | assing A to a number(code)                                |\n",
    "| code-point in Unicode standard | U+0000 to U+10FFFF (ie 1,114,111 code-points !)                                                                                                                             | A &rarr; U+0041                                           |\n",
    "| encoding                       | algorithm that converts **code-points** to **byte-sequences** and vice versa <br/> **purpose**: write it down in memory or disk                                             | ascii, UTF-8, UTF-16LE, latin_1, cp1252                   |\n",
    "| UTF-8                          | an encoding algorithm                                                                                                                                                       | A(U+0041) &rarr; \\x41 <br/> €(U+20AC) &rarr; \\xe2\\x82\\xac |\n",
    "| UTF-16LE                       | an encoding algorithm                                                                                                                                                       | A(U+0041) &rarr; \\x41\\x00 <br/> €(U+20AC) &rarr;\\xac\\x20  |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![example of encoding: address in book: Basic Encoders/Decoders | page : 123](./images/example_encoding.jpg)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| purpose                                                              | change                                     | dechange                                   | example : Identity function                                                                                                    |\n",
    "| -------------------------------------------------------------------- | ------------------------------------------ | ------------------------------------------ | ------------------------------------------------------------------------------------------------------------------------------ |\n",
    "| **character <span style=\"font-size: larger;\"> ⇔ </span> code-point** | ord(character) -> str                      | chr(code-point:int) -> int                 | chr(ord('😸'))<br/> ord(chr(0x1f638))                                                                                          |\n",
    "| **character <span style=\"font-size: larger;\"> ⇔ </span> bytes**      | my_str.encode(encoding=\"utf8\")             | my_bytes.decode(encoding=\"utf8\")           | '😸'.encode(encoding=\"utf8\").decode(encoding=\"utf8\") <br/> b'\\xf0\\x9f\\x98\\xb8'.decode(encoding=\"utf8\").encode(encoding=\"utf8\") |\n",
    "| **int <span style=\"font-size: larger;\"> ⇔ </span> bytes**            | my_int.to_bytes(length=1, byteorder=\"big\") | int.from_bytes(my_binary, byteorder=\"big\") | my_int = 65 <br/> my_binary = my_int.to_bytes(length=1, byteorder=\"big\") <br/> int.from_bytes(my_binary, byteorder=\"big\")      |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(65, 'A', 128568, '😸')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ord(\"A\"), chr(65), ord(\"😸\"), chr(128568)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'\\x124'\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(13330, 4660)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_int = 4660\n",
    "my_binary = my_int.to_bytes(length=2, byteorder=\"big\")\n",
    "print(my_binary)\n",
    "wrong_int = int.from_bytes(my_binary, byteorder=\"little\")\n",
    "correct_int = int.from_bytes(my_binary, byteorder=\"big\")\n",
    "wrong_int, correct_int"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note:**\n",
    "\n",
    "> **'cafe\\u0301'**, **'caf\\N{Latin Small Letter E with Acute}'**, **caf\\u00E9** **'café'** are the same !  \n",
    "> **0x41** , **65** both are int type\n",
    "\n",
    "```python\n",
    ">>> for word in 'cafe\\u0301', 'caf\\N{Latin Small Letter E with Acute}', 'caf\\u00E9', 'café':\n",
    ">>>     print(word)\n",
    "café, café, café, café\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "café, café, café, café, "
     ]
    }
   ],
   "source": [
    "for word in \"cafe\\u0301\", \"caf\\N{LATIN SMALL LETTER E WITH ACUTE}\", \"caf\\u00e9\", \"café\":\n",
    "    print(word, end=\", \", flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original word ==> café \n",
      "encoded word  ==> b'caf\\xc3\\xa9' \n",
      "decoded word  ==> café\n"
     ]
    }
   ],
   "source": [
    "word = \"café\"\n",
    "encoded_word = word.encode(\"utf8\")\n",
    "decoded_word = encoded_word.decode()  # 5 bytes: c, a, f,\\xc3\\xa9\n",
    "print(\n",
    "    f\"original word ==> {word} \\nencoded word  ==> {encoded_word} \\ndecoded word  ==> {decoded_word}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Question**: encode an integer value as str or raw?\n",
    "\n",
    "**INT32 range is :** $(-1 \\times 2^{31})$ to $(2^{31}-1)$  \n",
    "take an example with max int ie :\n",
    "\n",
    "```python\n",
    ">>> decimal_value = 2 ** 31 - 1\n",
    "2147483647\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "decoding raw decimal  ==> 4 bytes\n",
      "decoding str-decimal  ==> 10 bytes\n"
     ]
    }
   ],
   "source": [
    "decimal_value = 2**31 - 1  # int32 range is -1 * 2 ** 31 to 2 ** 31\n",
    "num_bytes = (\n",
    "    4  # int32 ie 4 bytes so  Number of bytes for the desired byte representation = 4\n",
    ")\n",
    "bytes_decimal = decimal_value.to_bytes(num_bytes, \"big\")\n",
    "print(f\"{'decoding raw decimal'.ljust(22)}==> {len(bytes_decimal)} bytes\")\n",
    "\n",
    "bytes_str_decimal = bytes(str(decimal_value), encoding=\"utf-8\")\n",
    "print(f\"{'decoding str-decimal'.ljust(22)}==> {len(bytes_str_decimal)} bytes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rules when displaying bytes:\n",
    "\n",
    "- For bytes with decimal codes 32 to 126—from space to ~ (tilde)—the ASCII char‐\n",
    "  acter itself is used.\n",
    "- For bytes corresponding to tab, newline, carriage return, and \\, the escape\n",
    "  sequences \\t, \\n, \\r, and \\\\ are used.\n",
    "- If both string delimiters ' and \" appear in the byte sequence, the whole sequence\n",
    "  is delimited by ', and any ' inside are escaped as \\'.\n",
    "  > ```python\n",
    "  > >>> byte_sequence = b'Hello \"world\"\\'s example'\n",
    "  > >>> string_representation = byte_sequence.decode('utf-8')\n",
    "  >\n",
    "  > >>> print(string_representation)\n",
    "  >  Hello \"world\"'s example\n",
    "  > ```\n",
    "- For other byte values, a hexadecimal escape sequence is used (e.g., \\x00 is the\n",
    "  null byte)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 bytes exist in encoded_word\n",
      "Based on utf8 ==> every  c, a, f corresponds to one byte and é corresponds to two bytes\n",
      "c ==> 99------- or 0x63----- or b'c'\n",
      "a ==> 97------- or 0x61----- or b'a'\n",
      "f ==> 102------ or 0x66----- or b'f'\n",
      "é ==> 50089---- or 0xc3a9--- or b'\\xc3\\xa9'\n"
     ]
    }
   ],
   "source": [
    "word = \"café\"\n",
    "encoded_word = word.encode(\"utf8\")\n",
    "\n",
    "print(f\"{len(encoded_word)} bytes exist in encoded_word\")\n",
    "print(\n",
    "    \"Based on utf8 ==> every  c, a, f corresponds to one byte and é corresponds to two bytes\"\n",
    ")\n",
    "# so print every char with its corresponding bytes\n",
    "# encoded_word[0].to_bytes(1, byteorder='big') equals to encoded_word[0:1]\n",
    "print(\n",
    "    f\"c ==> {encoded_word[0]:-<9} or {hex(encoded_word[0]):-<9} or {encoded_word[0:1]}\\\n",
    "\\na ==> {encoded_word[1]:-<9} or {hex(encoded_word[1]):-<9} or {encoded_word[1:2]}\\\n",
    "\\nf ==> {encoded_word[2]:-<9} or {hex(encoded_word[2]):-<9} or {encoded_word[2:3]}\\\n",
    "\\né ==> {int.from_bytes(encoded_word[3:], byteorder='big'):-<9} or \\\n",
    "{hex(int.from_bytes(encoded_word[3:], byteorder='big')):-<9} or {encoded_word[3:]}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### bytearray vs bytes\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Type      | status    |\n",
    "| --------- | --------- |\n",
    "| bytes     | immutable |\n",
    "| bytearray | mutable   |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'caf\\xc3\\xa9'\n",
      "bytearray(b'caf\\xc3\\xa9')\n"
     ]
    }
   ],
   "source": [
    "print(cafe := bytes(\"café\", encoding=\"utf_8\"))\n",
    "print(cafe2 := bytearray(cafe))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'bytes' object does not support item assignment\n",
      "<class 'bytearray'> is mutable\n"
     ]
    }
   ],
   "source": [
    "def mutable_or_not(cafe):\n",
    "    try:\n",
    "        cafe[0] = 12\n",
    "        print(type(cafe), \"is mutable\")\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "\n",
    "\n",
    "mutable_or_not(cafe)\n",
    "mutable_or_not(cafe2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "open(\"test_file\", \"wb\").write(encoded_word)\n",
    "open(\"test_file2\", \"w\").write(decoded_word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(False, True)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import keyword\n",
    "import builtins\n",
    "\n",
    "keywords = keyword.kwlist\n",
    "\"bytearray\" in keywords, \"bytearray\" in dir(builtins)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### what is CRLF?\n",
    "\n",
    "- Windows: Windows-based systems traditionally use the CRLF sequence (CR followed by LF) to represent line endings in text files.\n",
    "- Unix-like systems (Linux, macOS, etc.): Unix-like systems typically use the LF character alone to represent line endings.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b'Hi\\nNEWLINE2'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# open(\"test_file1\", 'w').write(\"hi\\nNEWLINE\")\n",
    "open(\"test_file2\", \"wb\").write(b\"Hi\\nNEWLINE2\")\n",
    "open(\"test_file2\", \"rb\").read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b'Hi\\nNEWLINE'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"Hi\\nNEWLINE\".encode()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## issues when encodig or decoding\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### encoding\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "UnicodeEncodeError",
     "evalue": "'charmap' codec can't encode character '\\xe3' in position 1: character maps to <undefined>",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUnicodeEncodeError\u001b[0m                        Traceback (most recent call last)",
      "\u001b[1;32md:\\FluentPython\\my_present\\fluent_ch4_v0.ipynb Cell 18\u001b[0m line \u001b[0;36m2\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/FluentPython/my_present/fluent_ch4_v0.ipynb#X22sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m city \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mSão Paulo\u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/FluentPython/my_present/fluent_ch4_v0.ipynb#X22sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m city\u001b[39m.\u001b[39;49mencode(\u001b[39m'\u001b[39;49m\u001b[39mcp437\u001b[39;49m\u001b[39m'\u001b[39;49m)\n",
      "File \u001b[1;32mc:\\Users\\ansar\\.conda\\envs\\fluent\\lib\\encodings\\cp437.py:12\u001b[0m, in \u001b[0;36mCodec.encode\u001b[1;34m(self, input, errors)\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mencode\u001b[39m(\u001b[39mself\u001b[39m,\u001b[39minput\u001b[39m,errors\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mstrict\u001b[39m\u001b[39m'\u001b[39m):\n\u001b[1;32m---> 12\u001b[0m     \u001b[39mreturn\u001b[39;00m codecs\u001b[39m.\u001b[39;49mcharmap_encode(\u001b[39minput\u001b[39;49m,errors,encoding_map)\n",
      "\u001b[1;31mUnicodeEncodeError\u001b[0m: 'charmap' codec can't encode character '\\xe3' in position 1: character maps to <undefined>"
     ]
    }
   ],
   "source": [
    "city = \"São Paulo\"\n",
    "city.encode(\"cp437\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "str.isascii(city)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b'So Paulo'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "city.encode(\"cp437\", errors=\"ignore\")\n",
    "# The error='ignore' handler skips characters that cannot be encoded\n",
    "# this is usually a very bad idea, leading to silent data los"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b'S?o Paulo'"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "city.encode(\"cp437\", errors=\"replace\")\n",
    "# When encoding, error='replace' substitutes unencodable characters with '?'\n",
    "# data is also lost, but users will get a clue that something is amiss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b'S&#227;o Paulo'"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "city.encode(\"cp437\", errors=\"xmlcharrefreplace\")\n",
    "# 'xmlcharrefreplace' replaces unencodable characters with an XML entity.\n",
    "# If you can’t use UTF, and you can’t afford to lose data, this is the only option."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### decoding\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "many legacy 8-bit encodings like `cp1252`, `iso8859_1`, `koi8_r` **are able to decode any stream of bytes, including random noise, without reporting errors.**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'MontrИal'"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "octets = b\"Montr\\xe9al\"\n",
    "octets.decode(\"koi8_r\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "ename": "UnicodeDecodeError",
     "evalue": "'utf-8' codec can't decode byte 0xe9 in position 5: invalid continuation byte",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUnicodeDecodeError\u001b[0m                        Traceback (most recent call last)",
      "\u001b[1;32md:\\FluentPython\\my_present\\fluent_ch4_v0.ipynb Cell 25\u001b[0m line \u001b[0;36m1\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/FluentPython/my_present/fluent_ch4_v0.ipynb#X60sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m octets\u001b[39m.\u001b[39;49mdecode(\u001b[39m'\u001b[39;49m\u001b[39mutf_8\u001b[39;49m\u001b[39m'\u001b[39;49m)\n",
      "\u001b[1;31mUnicodeDecodeError\u001b[0m: 'utf-8' codec can't decode byte 0xe9 in position 5: invalid continuation byte"
     ]
    }
   ],
   "source": [
    "octets.decode(\"utf_8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Montr�al'"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "octets.decode(\"utf_8\", errors=\"replace\")\n",
    "# Using 'replace' error handling, the \\xe9 is replaced by “�” (code point\n",
    "# U+FFFD), the official Unicode REPLACEMENT CHARACTER intended to represent\n",
    "# unknown characters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### When running a module\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you load a .py module containing non-UTF-8 data and no encoding declaration, you get a message like this:\n",
    "\n",
    "**SyntaxError:**  \n",
    "Non-UTF-8 code starting with '\\xe1' in file ola.py on line1,  \n",
    " but no encoding declared; see https://python.org/dev/peps/pep-0263/\n",
    "for details\n",
    "\n",
    "a likely scenario is opening a .py file created on Windows with cp1252. Note that this error hap‐\n",
    "pens even in Python for Windows, because the default encoding for Python 3 source\n",
    "is UTF-8 across all platforms\n",
    "\n",
    "solution: at the beginning:\n",
    "\n",
    "```python\n",
    "# coding: cp1252\n",
    "print('Olá, Mundo!')\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How to Discover the Encoding of a Byte Sequence\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Short answer: you can’t**\n",
    "\n",
    "| Sign in Bytes                                          | Conclusion                               | Why                                                                 |\n",
    "| ------------------------------------------------------ | ---------------------------------------- | ------------------------------------------------------------------- |\n",
    "| contain byte values over 127                           | not ASCII                                | ascii is 0 to 127                                                   |\n",
    "| b'\\x00' bytes are common                               | 32-bit encoding, and not an 8-bit scheme | null characters in plain text are bugs                              |\n",
    "| b'\\x20\\x00' bytes are common                           | UTF-16LE                                 | more likely to represent the space character (U+0020) in a UTF-16LE |\n",
    "| detect BOM at starting <br/> ex: b'\\xef\\xbb\\xbf\\ ... ' | see b'\\xef\\xbb\\xbf\\ so likely UTF-8 file | b'\\xef\\xbb\\xbf' BOM of utf-8-sig <br/> other codec may have BOM too |\n",
    "\n",
    "**note** : A good library to detect encoding is [chardet](https://pypi.org/project/chardet/)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Big endian vs little endian\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Understanding endianness is important when working with multi-byte values, such as integers, floating-point numbers, and character encodings like UTF-16. It helps ensure that the bytes are interpreted correctly based on the chosen byte order\n",
    "\n",
    "_least significant byte(LSB)_ is stored at the lowest memory address, while the _most significant byte (MSB)_ is stored at the highest memory address\n",
    "\n",
    "**Example:**\n",
    "\n",
    "> **big-endian (storing 0x1234 or 4660):**  \n",
    "> |memory address : 0x1000 |memory address : 0x1001 |\n",
    "> |---------|---------|\n",
    "> |value: 0x12 | value: 0x34 |  \n",
    "> <br/>\n",
    "\n",
    "> **little-endian (storing 0x1234 or 4660):**  \n",
    "> |memory address : 0x1000 |memory address : 0x1001 |\n",
    "> |---------|---------|\n",
    "> |value: 0x34 | value: 0x12 |\n",
    "\n",
    "see cpu standard of your system:\n",
    "\n",
    "```python\n",
    "import sys\n",
    ">>> sys.byteorder\n",
    "'little'\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What is BOM(byte order mark) ?\n",
    "\n",
    "```python\n",
    " u16 = 'El Niño'.encode('utf_16')\n",
    ">>> u16\n",
    "b'\\xff\\xfeE\\x00l\\x00 \\x00N\\x00i\\x00\\xf1\\x00o\\x00'\n",
    "```\n",
    "\n",
    "**\\xff\\xfe &rarr; BOM**\n",
    "\n",
    "in utf-16le or utf-16le BOM is not generated\n",
    "\n",
    "example of little-endian and big-endian in utf-16 encoding:  \n",
    "e(U+0065) &rarr; 2 Byte : (LSB)&rarr; 0x65 | (MSB)&rarr; 0x00\n",
    "\n",
    "- utf-16le :\n",
    "\n",
    "  > Byte 0: 0x65  \n",
    "  > Byte 1: 0x00 <br/>\n",
    "\n",
    "- utf-16be :\n",
    "  > Byte 0: 0x00  \n",
    "  > Byte 1: 0x65\n",
    "\n",
    "```python\n",
    ">>> u16le = 'El Niño'.encode('utf_16le')\n",
    ">>> list(u16le)\n",
    "[69, 0, 108, 0, 32, 0, 78, 0, 105, 0, 241, 0, 111, 0]\n",
    ">>> u16be = 'El Niño'.encode('utf_16be')\n",
    ">>> list(u16be)\n",
    "[0, 69, 0, 108, 0, 32, 0, 78, 0, 105, 0, 241, 0, 111]\n",
    "```\n",
    "\n",
    "**One big advantage of UTF-8 is that it produces the same byte sequence regardless of machine endianness, so no BOM is needed.**\n",
    "\n",
    "```python\n",
    ">>> 'El Niño'.encode('utf_8')\n",
    "b'El Ni\\xc3\\xb1o'\n",
    ">>> 'El Niño'.encode('utf_8_sig')\n",
    "b'\\xef\\xbb\\xbfEl Ni\\xc3\\xb1o'\n",
    "```\n",
    "\n",
    "[codecs documentation](https://docs.python.org/3/library/codecs.html#encodings-and-unicode) says: “In UTF-8, the use of the BOM is discouraged and should generally be avoided.”\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Handling Text Files\n",
    "\n",
    "recommand specify encoding when write or read txt files\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "open(\"cafe.txt\", \"w\", encoding=\"utf_8\").write(\"café\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file content : café \n",
      "file size : 5\n",
      "file encoding : utf-8\n"
     ]
    }
   ],
   "source": [
    "f = open(\"cafe.txt\", encoding=\"utf-8\")\n",
    "import os\n",
    "\n",
    "print(\n",
    "    f\"file content : {f.read()} \\nfile size : {os.stat('cafe.txt').st_size}\\nfile encoding : {f.encoding}\"\n",
    ")\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note**: If you omit the encoding argument when opening a file, the default is given by :\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'UTF-8'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import locale\n",
    "\n",
    "locale.getpreferredencoding()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**str <span style=\"font-size: larger;\"> ⇔ </span> locale.getpreferredencoding() <span style=\"font-size: larger;\"> ⇔ </span> bytes**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```bash\n",
    "chcp\n",
    "$$ Active code page: 437\n",
    "```\n",
    "\n",
    "**Code page 437**, IBM PC-437 or simply **CP437**, was an early character **encoding used by IBM in its original IBM PC** and compatible systems.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " locale.getpreferredencoding() -> 'UTF-8'\n",
      "                 type(my_file) -> <class '_io.TextIOWrapper'>\n",
      "              my_file.encoding -> 'UTF-8'\n",
      "           sys.stdout.isatty() -> True\n",
      "           sys.stdout.encoding -> 'utf-8'\n",
      "            sys.stdin.isatty() -> True\n",
      "            sys.stdin.encoding -> 'utf-8'\n",
      "           sys.stderr.isatty() -> True\n",
      "           sys.stderr.encoding -> 'utf-8'\n",
      "      sys.getdefaultencoding() -> 'utf-8'\n",
      "   sys.getfilesystemencoding() -> 'utf-8'\n"
     ]
    }
   ],
   "source": [
    "!python  utils/default_encodings.py # page 134\n",
    "# stdout ==> display\n",
    "# stdin ==> type input\n",
    "# stderr ==> error showing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It’s weird that chcp and sys.stdout.encoding\n",
    "say different things when stdout is writing to the console, but it’s great that now we\n",
    "can print Unicode strings without encoding errors on Windows—unless the user\n",
    "redirects output to a file That does not mean all your favorite emojis will appear in the console: that also depends on the font the console is using\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Fortunately these codes run well in win11 terminal!** based on fluent python book these codes will not run well on win10  \n",
    "if see any problem : console font doesn’t have the glyph to display it\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.10.13 (main, Oct 18 2023, 01:54:08) [GCC 11.3.1 20221121 (Red Hat 11.3.1-4)]\n",
      "\n",
      "sys.stdout.isatty(): False\n",
      "sys.stdout.encoding: UTF-8\n",
      "\n",
      "Trying to output HORIZONTAL ELLIPSIS:\n",
      "…\n",
      "Trying to output INFINITY:\n",
      "∞\n",
      "Trying to output CIRCLED NUMBER FORTY TWO:\n",
      "㊷\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "from unicodedata import name\n",
    "\n",
    "print(sys.version)\n",
    "print()\n",
    "print(\"sys.stdout.isatty():\", sys.stdout.isatty())\n",
    "print(\"sys.stdout.encoding:\", sys.stdout.encoding)\n",
    "print()\n",
    "test_chars = [\n",
    "    \"\\N{HORIZONTAL ELLIPSIS}\",  # exists in cp1252, not in cp437\n",
    "    \"\\N{INFINITY}\",  # exists in cp437, not in cp1252\n",
    "    \"\\N{CIRCLED NUMBER FORTY TWO}\",  # not in cp437 or in cp1252\n",
    "]\n",
    "for char in test_chars:\n",
    "    print(f\"Trying to output {name(char)}:\")\n",
    "    print(char)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "when python version > 3.6 :\n",
    "\n",
    "> If PYTHONLEGACYWINDOWSSTDIO is not set or is set to an empty string, the encoding for standard I/O is as follows:\n",
    ">\n",
    "> - For interactive I/O (when running Python interactively in a terminal), the encoding is UTF-8.\n",
    "> - If the output/input is redirected to/from a file, the encoding is determined by locale.getpreferredencoding().\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalizing unicode\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| unicodedata.normalize(normalization*from*, char\\_) | meaning                                                                                     |\n",
    "| -------------------------------------------------- | ------------------------------------------------------------------------------------------- |\n",
    "| **NFC**                                            | to produce the shortest equivalent string (safe)                                            |\n",
    "| NFD                                                | expanding composed characters into base characters and separate combining characters (safe) |\n",
    "| NFKC                                               | The goal is to have a standardized form for compatibility characters (search&index)         |\n",
    "| NFKD                                               | The goal is to have a standardized form for compatibility characters (search&index)         |\n",
    "\n",
    "```python\n",
    ">>> from unicodedata import normalize\n",
    ">>> s1 = 'café'\n",
    ">>> s2 = 'cafe\\N{COMBINING ACUTE ACCENT}'\n",
    ">>> len(s1), len(s2)\n",
    "(4, 5)\n",
    ">>> len(normalize('NFC', s1)), len(normalize('NFC', s2))\n",
    "(4, 4)\n",
    ">>> len(normalize('NFD', s1)), len(normalize('NFD', s2))\n",
    "(5, 5)\n",
    ">>> normalize('NFC', s1) == normalize('NFC', s2)\n",
    "True\n",
    ">>> normalize('NFD', s1) == normalize('NFD', s2)\n",
    "True\n",
    "```\n",
    "\n",
    "Keyboard drivers usually generate composed characters, so text typed by users will be\n",
    "in NFC by default.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note:** **NFKC or NFKD may lose or distort information**, but they can produce convenient intermediate representations for searching and indexing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "½  ==>  1⁄2\n",
      "1\tDIGIT ONE\n",
      "⁄\tFRACTION SLASH\n",
      "2\tDIGIT TWO\n",
      "4²  ==>  42\n"
     ]
    }
   ],
   "source": [
    "from unicodedata import normalize, name\n",
    "\n",
    "half = \"\\N{VULGAR FRACTION ONE HALF}\"\n",
    "print(half, \" ==> \", normalize(\"NFKC\", half))\n",
    "\n",
    "for char in normalize(\"NFKC\", half):\n",
    "    print(char, name(char), sep=\"\\t\")\n",
    "four_squared = \"4²\"\n",
    "print(four_squared, \" ==> \", normalize(\"NFKC\", four_squared))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### case folding\n",
    "\n",
    "case folding is usefull When preparing text for searching or indexing  \n",
    "**Case folding is essentially converting all text to lowercase, with some additional**\n",
    "transformations. It is supported by the str.casefold() method  \n",
    "There are nearly 300 code points for which str.casefold() and str.lower() return\n",
    "different results.  \n",
    "It is **good when case-insensitive comparisons but with some problems**  \n",
    "recommand to use **normalize('NFC', str1).casefold()**\n",
    "\n",
    "```python\n",
    ">>> eszett = 'ß'\n",
    ">>> name(eszett)\n",
    "'LATIN SMALL LETTER SHARP S'\n",
    ">>> eszett_cf = eszett.casefold()\n",
    ">>> eszett, eszett_cf\n",
    "('ß', 'ss')\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| purpose                                                     | recommend                         |\n",
    "| ----------------------------------------------------------- | --------------------------------- |\n",
    "| safe normalization                                          | NFC normalization                 |\n",
    "| case-insentive search                                       | NFC + casefold()                  |\n",
    "| decompose character into base character and combining marks | NFD                               |\n",
    "| check \\_chr\\_\\_ to find out diacritics?                     | unicodedata.combining(\\_char\\_\\_) |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### sort str\n",
    "\n",
    "Python sorts sequences of any type by comparing the items in each sequence one by one.  \n",
    "For strings, this means comparing the code points. Unfortunately, this produces unacceptable results for anyone who uses non-ASCII characters  \n",
    "**pyuca : pure-Python implementation of the Unicode Collation Algorithm (UCA)**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "import locale\n",
    "my_locale = locale.setlocale(locale.LC_COLLATE, 'pt_BR.UTF-8')\n",
    "print(my_locale)\n",
    "fruits = ['caju', 'atemoia', 'cajá', 'açaí', 'acerola']\n",
    "sorted_fruits = sorted(fruits, key=locale.strxfrm)\n",
    "print(sorted_fruits)\n",
    "\n",
    "```\n",
    "\n",
    "```python\n",
    ">>> import pyuca\n",
    ">>> coll = pyuca.Collator()\n",
    ">>> fruits = ['caju', 'atemoia', 'cajá', 'açaí', 'acerola']\n",
    ">>> sorted_fruits = sorted(fruits, key=coll.sort_key)\n",
    ">>> sorted_fruits\n",
    "['açaí', 'acerola', 'atemoia', 'cajá', 'caju']\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Unicode Database\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "you can see more information about characters  \n",
    "see this char('😸') info from [compart.com](https://www.compart.com/en/unicode/U+1F638)\n",
    "\n",
    "the Unicode database records whether a character is printable, is a letter, is\n",
    "a decimal digit, or is some other numeric symbol. That’s how the str methods isal\n",
    "pha, isprintable, isdecimal, and isnumeric work. str.casefold also uses infor‐\n",
    "mation from a Unicode table.\n",
    "\n",
    "**tip:** more information on [unicodedata](https://docs.python.org/3/library/unicodedata.html)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The U+ code for ⑦ ----------------- U+2466\n",
      "name of ⑦ char--------------------- CIRCLED DIGIT SEVEN\n",
      "char is decimal ?------------------ False\n",
      "char is digit ?-------------------- False\n",
      "char is number ? ------------------ True\n",
      "equal number of char sign --------- 7.0\n"
     ]
    }
   ],
   "source": [
    "import unicodedata\n",
    "import re\n",
    "\n",
    "re_digit = re.compile(r\"\\d\")\n",
    "# regex is more usefull: https://pypi.org/project/regex/\n",
    "\n",
    "\n",
    "def better_print(input_expalin, value):\n",
    "    print(f\"{input_expalin:-<35} {value}\")\n",
    "\n",
    "\n",
    "def info_char(character):\n",
    "    code_point = ord(character)\n",
    "    unicode_code = f\"U+{code_point:04X}\"\n",
    "    better_print(f\"The U+ code for {character} \", unicode_code)\n",
    "    better_print(f\"name of {character} char\", unicodedata.name(character))\n",
    "    better_print(\"char is decimal ?\", character.isdecimal())\n",
    "    better_print(f\"char is digit ?\", bool(re_digit.match(character)))\n",
    "    better_print(\"char is number ? \", character.isnumeric())\n",
    "    try:  # or you could first check it is a number so see its number to avoid error rasing\n",
    "        better_print(\"equal number of char sign \", unicodedata.numeric(character))\n",
    "    except:\n",
    "        print(\"char is not numeric!\")\n",
    "\n",
    "\n",
    "character0 = \"\\N{CIRCLED NUMBER FORTY TWO}\"  # or  \"㊷\"\n",
    "character1 = \"\\N{GRINNING CAT FACE WITH SMILING EYES}\"  #  or '😸'\n",
    "character2 = \"\\u2466\"  # ⑦\n",
    "character3 = \"5\"\n",
    "info_char(character2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dual-Mode str and bytes APIs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### re api\n",
    "\n",
    "regular expressions is valid on str and bytes,  \n",
    "**in bytes api, bytes outside the ASCII range are treated as nondigits and nonword characters.**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text\n",
      " 'Ramanujan saw ௧௭௨௯ as 1729 = 1³ + 12³ = 9³ + 10³.'\n",
      "Numbers\n",
      " str : ['௧௭௨௯', '1729', '1', '12', '9', '10']\n",
      " bytes: [b'1729', b'1', b'12', b'9', b'10']\n",
      "Words\n",
      " str : ['Ramanujan', 'saw', '௧௭௨௯', 'as', '1729', '1³', '12³', '9³', '10³']\n",
      " bytes: [b'Ramanujan', b'saw', b'as', b'1729', b'1', b'12', b'9', b'10']\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "re_numbers_str = re.compile(r\"\\d+\")\n",
    "re_words_str = re.compile(r\"\\w+\")\n",
    "re_numbers_bytes = re.compile(rb\"\\d+\")\n",
    "re_words_bytes = re.compile(rb\"\\w+\")\n",
    "text_str = \"Ramanujan saw \\u0be7\\u0bed\\u0be8\\u0bef\" \" as 1729 = 1³ + 12³ = 9³ + 10³.\"\n",
    "text_bytes = text_str.encode(\"utf_8\")\n",
    "print(f\"Text\\n {text_str!r}\")\n",
    "print(\"Numbers\")\n",
    "print(\" str :\", re_numbers_str.findall(text_str))\n",
    "print(\" bytes:\", re_numbers_bytes.findall(text_bytes))\n",
    "print(\"Words\")\n",
    "print(\" str :\", re_words_str.findall(text_str))\n",
    "print(\" bytes:\", re_words_bytes.findall(text_bytes))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### os api\n",
    "\n",
    "The GNU/Linux kernel is not Unicode savvy, so in the real world you may find file‐\n",
    "names made of byte sequences that are not valid in any sensible encoding scheme,\n",
    "and cannot be decoded to str, If one such function is called with a str\n",
    "argument, the argument will be automatically converted using the codec named by\n",
    "sys.getfilesystemencoding(), and the OS response will be decoded with the same\n",
    "codec.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['2',\n",
       "  'cafe.txt',\n",
       "  'ch4_v1.ipynb',\n",
       "  'char_name.jpg',\n",
       "  'dummy',\n",
       "  'example_encoding.jpg',\n",
       "  'test_file',\n",
       "  'test_file2',\n",
       "  'utils',\n",
       "  '__pycache__'],\n",
       " [b'2',\n",
       "  b'cafe.txt',\n",
       "  b'ch4_v1.ipynb',\n",
       "  b'char_name.jpg',\n",
       "  b'dummy',\n",
       "  b'example_encoding.jpg',\n",
       "  b'test_file',\n",
       "  b'test_file2',\n",
       "  b'utils',\n",
       "  b'__pycache__'])"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "os.listdir(\".\"), os.listdir(b\".\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lecturers\n",
    "\n",
    "1. Mohammad Ansarifard, present date : 04-13-2023, `Linkedin` : [linkedin.com/in/mohammad-ansarifard](https://www.linkedin.com/in/mohammad-ansarifard)\n",
    "2. Mehrdad biukian date: 04-10-2023, [LinkedIn](www.linkedin.com/in/mehrdad-biukian-naeini)\n",
    "\n",
    "#### Reviewers\n",
    "\n",
    "1.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fluent",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
